
data.dir = ./data
tmp.dir = /tmp

mapdb.dir = mapdb
mapdb.commit = 1000

lucene.index = lucene

 
spot.commonness.threshold = 0.005
spot.probability.threshold = 0.02



#number of entities in the collection
w = 4700000

#relatedness function
relatedness=milne

#how many words consider around the spot
context.window.size = 50

ram.incoming.nodes = graph/incoming-edges.bin
ram.outcoming.nodes = graph/outcoming-edges.bin

# use the context text to rank the entities (affects performance)
rank.by.similarity = true
# use the prior probability (e|s) aka commonness to rank the entities 
rank.by.prior = false

lucene.wiki.id = wiki2lucene-map.bin

# type of the spot repository [mapfile|mapdb]
spot.repository=ram
relatedness.cache.size=5000
spotter.cache.size=10000

prior.threshold=0.03


#the file containing the spots
spots = spot/spots.tsv.gz
# the file containing the mininal perfect hash for each spot
ram.spot.perfect.hash = spot/ram/minimal-perfect-hash.bin
#the offset of the spot in the encoded data file
ram.spot.offsets = spot/ram/offsets.gz
#the offset of the spot in the encoded data file, compressed with elias fano
ram.spot.offsets.ef = spot/ram/offsets.eliasfano.bin
#the file with the encoded spots
ram.spot.data.bin = spot/ram/spots.bin

wikiminer.classifier = ./data/wikiminer/model.arff





