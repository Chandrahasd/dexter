
data.dir = ./data
tmp.dir = /tmp

jdbm.dir = jdbm
jdbm.commit = 1000

lucene.index = ./data/lucene
hadoop.spots = ./data/spot-index
hadoop.id2incoming = ./data/id2incoming

#ignore spots with to much entities associated 
# polisemy = 1 - (1/#entities) 
spot.polisemy.threshold = 0.9
spot.commonness.threshold = 0.005
spot.probability.threshold = 0.02

#number of entities in the collection
w = 4700000

#relatedness function
relatedness=milne

#how many words consider around the spot
context.window.size= 50

incoming.nodes= ./data/graph/incoming-edges.tsv.gz
outcoming.nodes= ./data/graph/outcoming-edges.tsv.gz

ram.incoming.nodes= ./data/graph/incoming-edges.bin
ram.outcoming.nodes= ./data/graph/outcoming-edges.bin

# use the context text to rank the entities (affects performance)
rank.by.similarity=false
rank.by.prior=true
lucene.wiki.id =./data/lucene/wiki2lucene-map.bin

# type of the spot repository [mapfile|mapdb]
spot.repository=ram
relatedness.cache.size=5000
spotter.cache.size=10000

# where to store the minimal perfect hash function for spots
ram.spot.hash.values = ./data/spot/spot-hashes.gz

ram.spot.perfect.hash = ./data/spot/minimal-perfect-hash.bin
ram.spot.offsets = ./data/spot/offsets.gz
ram.spot.offsets.ef = ./data/spot/offsets.eliasfano.bin
ram.spot.data.bin = ./data/spot/spots.bin

spots = ./data/spot/spots.tsv.gz

prior.threshold=0.01

wikiminer.classifier = ./data/wikiminer/model.arff

tagme.window.size=30
tagme.epsilon = 0.7
